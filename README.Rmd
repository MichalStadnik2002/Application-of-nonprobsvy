---
title: "Verification of Estimators for Non-Probability Samples in R"
author: "Michał Stadnik"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

In this project I investigated the concepts of `nonprobsvy` library to check how different estimators behave. There is a simulation of a population where weekly time spent on sport activities depends on sex, BMI and age. From this population a non-probability and a probability sample are drawn. Then various estimators provided by `nonprobsvy` library (IPW, MI, DR) are used to estimate average weekly time spent on sport. Finally all estimates were presented on the graph and compared to the true mean.

## Motivation

The `nonprobsvy` library was created to implement solutions to the non-probability samples problem. For example, suppose we have an online survey and want to estimate a parameter for the whole population based on it. Most likely, a majority of the answers would be given by young people, and older people would be underrepresented in our sample. If only we have some external, unbiased data containing variables that are correlated with our outcome of interest, we can use the tools from the `nonprobsvy` library to correct for this bias.

I created this project because I want to understand the basics of the non-probability samples problem and to prepare for applying for an internship in a project developing the `nonprobsvy` library. This work is based on the article "nonprobsvy – An R package for modern methods for non-probability surveys" by M. Beręsewicz, P. Chlebicki, and Ł. Chrostowski.

## Methodology

### Generating data

I used three auxiliary variables:
- `sex` - generated from binomial distribution with a probability of 0.51, where 1 indicates female,
- `bmi` - generated from gamma distribution with shape parameter equals 4.5 and scale equals 2.2. The whole distribution was shifted by adding 14 so that the average BMI was about 23,
- `age` - generated from beta distribution with alpha = 2 and beta = 3. Then it was scaled and shifted appropriately. It was assumed that the age ranges from 18 to 80 years old.

The target variable: `time_sport` is generated by adding some normal (with mean = 0 and standard deviation = 3) error factor to `base_time_sport`. To prevent negative time values the maximum of this sum and 0 was taken.

The core of the whole generation: `base_time_sport` is generated from the following formula:

$base\_time\_sport = \beta_0 + \beta_{age} age + \beta_{age2} age^2 + \beta_{sex} sex + \beta_{BMI} (bmi-23)^2 + \beta_{sex\_BMI2} sex \cdot (bmi-23)^2$,

where betas are coefficients. In simulation I used:

- $\beta_0 = 5$, I assumed the base weekly time spent on sport is 5 hours,
- $\beta_{age} = 0.15$,
- $\beta_{age2} = -0.002$, these coefficients represent that from 18 to about 40 time spent on sport grows but over 40 it decreases,
- $\beta_{sex} = -0.5$, I assumed that male slightly more often do sports activities,
- $\beta_{BMI} = -0.05$, this with used formula ($(bmi-23)^2$) indicates that people with BMI around average spent more time on sport, than people with high or low BMI,
- $\beta_{sex\_BMI2} = 0.01$, the effect of high or low BMI is slightly weaker for women than for male.

The whole population in simulation has 10 000 individuals.

### Mechanism of selection

I assumed that data in non-probability sample were collected from some online survey. In order to get this effect I used the logistic formula to get probabilities of taking the survey $\pi_{NP}$ using the following formula:

$\pi_{NP} = \frac{1}{1+e^{- logit\_pi}}$,
$logit\_pi = \gamma_0 + \gamma_1 age + \gamma_2 (bmi-23)^2$,

where gammas are coefficients. In simulation I used:

- $\gamma_0 = -2.5$,
- $\gamma_1 = -0.05$, the probability of participation decreases with age,
- $\gamma_2 = -0.1$, this with used formula ($(bmi-23)^2$) corresponds to the assumption that people with BMI around average are more likely to take a survey about sport, than people with high or low BMI.

A sample of 1000 individuals was drawn with probabilities $\pi_{NP}$.

To ensure no overlap between the samples (as required by the package), the probability sample was drawn uniformly from the population excluding individuals already selected for the non-probability sample. The probability sample has 2000 records.

### Compared estimators

I used all three kinds of estimators: Mass Imputation (MI), Inverse Probability Weighting (IPW) and Doubly Robust (DR). Within each approach I used following methods:

- Mass Imputation:
  - semi-parametric method (MI-GLM),
  - semi-parametric method with variable selection,
  - kernel smoothing (MI-NPAR),
  - nearest neighbour matching (MI-NN) with:
    - $k = 2$,
    - $k = 5$,
    - $k = 10$,
  - predictive mean matching with matching predicted to predicted (MI-PMM-A),
  - predictive mean matching with matching predicted to observed (MI-PMM-B),
- Inverse Probability Weighting:
  - by Maximum Pseudo-Likelihood Estimator (MLE),
  - by Generalized Estimating Equations (GEE):
    - with h function: $h(x_i, \gamma) = \frac{x_i}{\pi(x_i, \gamma)}$ (`gee_h_fun = 1`),
    - with h function: $h(x_i, \gamma) = x_i$ (`gee_h_fun = 2`),
    - with h function: `gee_h_fun = 1` and variable selection,
- Doubly Robust:
  - MI-GLM and MLE Estimator,
  - MI-GLM and GEE Estimator with `gee_h_fun = 1`,
  - MI-GLM and MLE Estimator with bias correction,
  - MI-GLM and GEE Estimator with `gee_h_fun = 1` with bias correction,

For reference purposes I also calculated the true population mean, and the naive mean, i.e. ordinary mean in non-probability sample.
